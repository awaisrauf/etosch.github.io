---
layout: post
title: 'Bug Detection II : Breakoff'
type: post
published: false
status: draft
categories: []
tags: []
meta:
  _edit_last: '20775'
author:
  login: etosch
  email: etosch@cns.umass.edu
  display_name: Emma Tosch
  first_name: Emma
  last_name: Tosch
---
<blockquote>
Finally, it is important to monitor and record the rate at which people begin an experiment but do not finish. This is typically not a problem in laboratory studies since the social pressure of getting up a walking out of the lab is much higher than it is online. However, dropout rates can interact in complex ways with dependent measures such as accuracy (low performing individuals may be more likely to drop out). We recommend that, perhaps unlike a typical laboratory study, all Internet experiments report dropout rates as a function of condition.</p>
<p>Dropout rate may also depend on task length, financial incentive, and other motivations to complete the task. Our studies validated a range of task lengths from 5â€“30 min with a range of relatively low financial incentives. Across tasks, dropout rates were not prohibitively high, and we expect that these rates would naturally change to the extent that subjects are given incentive to complete the task at hand. We did not conduct lengthier experiments (e.g., more than one hour long, or multi-day experiments); however, our experience leads us to believe that these types of experiments could be conducted by increasing pay and restricting the experiment to highly motivated and accomplished workers. (<a href="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0057410">Crump et al 2013</a>)
</p></blockquote>
<p>Our algorithm for detecting breakoff is quite simple, but implementing it has presented some challenges. AMT does not allow requesters to record information from a HIT if the worker has not elected to submit their work. This makes measure abandonment difficult. Typically researchers have dealt with this by pointing workers to externally hosted surveys. Services like SurveyMonkey and Qualtrics allow users to generate confirmation codes, which will be presented to respondents upon completion of the survey. The worker then enters that code into the HIT as evidence of having completed the survey. The requester verifies the code and on that basis awards payment. </p>
<p>We would like to keep the respondent on the same page as the </p>
